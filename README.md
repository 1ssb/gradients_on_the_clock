# ANU Techlauncher project: Gradients on the Clock

# Phase 1: Ground Preparation --> Design the Prototype

## Setup Initial Computation

### Objective
Establish a foundational computation setup involving a microcontroller and FPGA interfaced with your PC to perform basic gradient descent computations. The focus is on developing an efficient software and hardware pipeline that supports automatic differentiation.

### Steps
1. **Select Hardware:** Choose a microcontroller and FPGA board that meet the project's computational power and energy efficiency requirements.
2. **Initial Setup:** Interface the microcontroller with the FPGA board and connect this setup to your PC.
3. **Software Development:** Write basic software to test the setup's communication and computational capabilities, starting with simple operations.
4. **Evaluation:** Assess efficiency, reliability, and power consumption to identify any bottlenecks or limitations.

### Checkpoint
An efficient software-hardware pipeline capable of basic gradient descent computations and supporting automatic differentiation.

## Design a Basic Gradient Box

### Objective
Create a physical housing for the computational setup that is power-efficient and scalable.

### Steps
1. **Design Phase:** Use 3D modeling software for designing a structure that accommodates all components while ensuring easy access and efficient heat dissipation.
2. **Material Selection:** Choose materials that are lightweight, durable, and provide adequate electromagnetic interference shielding.
3. **Prototype Manufacturing:** 3D print or construct the Gradient Box prototype.
4. **Assembly:** Securely install all components within the Gradient Box.

### Inventory Decision
Select components that balance performance and power consumption, including microcontrollers, FPGA boards, displays, and peripherals.

### Challenge
Achieve high power efficiency without compromising on performance or scalability.

## Perform an Initial Capacity Study

### Objective
Test the computational capabilities of the setup through key operations fundamental to gradient descent and automatic differentiation.

### Steps
1. **Matrix Operations:** Implement matrix multiplication and inversion algorithms in C, optimizing for speed and efficiency.
2. **AutoDiff Pipeline Setup:** Develop a basic automatic differentiation pipeline integrated with gradient descent computation.
3. **C++ Integration and CUDA Exploration:** Extend the framework to include C++ modules and explore CUDA libraries for GPU acceleration potential.

## Conduct a Literature Review and Develop a Project Website

### Objective
Perform an extensive literature review related to gradient descent, automatic differentiation, and power efficiency in computing hardware. Develop a website to document project progress.

### Steps
1. **Literature Review:** Gather information from academic databases, focusing on recent research and methodologies in optimization and energy-efficient computing.
2. **Website Development:** Create a project website with objectives, progress updates, a blog, and a repository of resources.
3. **Documentation:** Begin drafting comprehensive engineering documentation based on findings, design decisions, and tests.

### Outcome
A foundational knowledge base and a public-facing platform to share project progress, engaging with the community and potential collaborators.
