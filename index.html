<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-store">
    <title>Gradients on the Clock</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
    <style>
   html {
    height: 100%;
    margin: 0;
    padding: 0;
    font-family: 'Lato', sans-serif;
    transition: background-color 0.3s, color 0.3s;
    overflow-x: hidden;
    box-sizing: border-box; /* Ensures padding doesn't affect overall width */
}

body {
    font-family: 'Lato', sans-serif;
    margin: 0;
    padding: 5px;
    display: flex;
    flex-direction: column;
    min-height: 100vh;
    transition: background-color 0.3s, color 0.3s;
    align-items: center; /* Center aligns all flex children including header and footer */
}

.header {
    width: 100%; /* Ensures header spans the full width */
    display: flex;
    justify-content: space-between; /* This should push the title to the left and buttons to the right */
    flex-direction: row;
    align-items: center;
    padding: 20px;
    background-color: #f8f9fa;
}

.header .title {
    font-size: 24px;
    font-weight: bold;
    /* If you want the title to not stick hard to the left, you could add some margin or padding on the left side */
    margin-left: 20px; /* Adjust this value as needed */
}

.buttons {
    display: flex;
    gap: 10px;
}

.theme-toggle {
    background: none;
    border: none;
    font-size: 24px;
    cursor: pointer;
}

.theme-toggle i {
    color: blue; /* Default color for light mode */
}

.container {
    flex: 1;
    display: flex;
    flex-direction: column;
    align-items: center; /* Ensures all cards are centered in the container */
    justify-content: flex-start;
    padding: 20px;
    text-align: left;
    width: 100%; /* Ensures container takes full width */
}

.card {
    background-color: #ffffff;
    border-radius: 10px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    padding: 20px;
    width: 90%; /* Width less than 100% to account for padding */
    margin-bottom: 20px;
    flex-shrink: 0; /* Prevent shrinking */
}

.card h2, .card h3 {
    color: blue;
}

.bio-text {
    text-align: justify;
}

.bio-section {
    margin-bottom: 20px;
}

.dark-mode {
    background-color: #121212;
    color: #e0e0e0;
}

.dark-mode .card {
    background-color: #1c1c1c;
    color: #e0e0e0;
}

.dark-mode .card h2, .dark-mode .card h3 {
    color: yellow;
}

.dark-mode .header {
    background-color: #1c1c1c;
}

.dark-mode .theme-toggle i {
    color: white; /* Color for dark mode */
}

a {
    color: blue;
    text-decoration: none;
}

a:hover {
    text-decoration: underline;
}

.dark-mode a {
   color: white;
   text-decoration: underline;
}

.button1 {
    display: inline-block;
    padding: 10px 15px;
    font-size: 16px;
    color: #ffffff;
    background-color: #007bff;
    border: none;
    border-radius: 5px;
    text-decoration: none;
    margin: 5px 0;
}

.button1:hover {
    background-color: #0056b3;
}

@media (max-width: 768px) {
    .header .title {
        font-size: 18px;
    }
    .theme-toggle {
        font-size: 20px;
    }
    .container {
        padding: 10px;
    }
    .card {
        width: 100%; /* Makes card width 100% within the container */
    }
    .button1 {
        font-size: 14px;
    }
}

footer {
    text-align: center;
    padding: 20px;
    background-color: #f8f9fa;
    font-size: 14px;
    width: 100%;
}

.dark-mode footer {
    background-color: #333 !important;
}

    </style>
</head>
<body>
    <header class="header">
        <div class="title">Gradients on the Clock [Positions are filling up (5/7) filled. Please apply sooner than later.]</div>
        <div class="buttons">
            <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
                <i class="fas fa-moon"></i>
            </button>
        </div>
    </header>
    <div class="container">
        <div class="card">
            <h2>What is this project?</h2>
            <p>This is a pioneering venture at the intersection of microprocessors, optimization, and deep learning. This project aims to enhance the capabilities of automatic differentiation engines critical to deep learning on microprocessors. Our theme centers around Robotic Learning, where we aspire to create robots that can learn and adapt on the go.</p>
            <p>Unlike traditional project structures, this initiative follows an inverted format where the team drives decisions and sets targets, fostering a collaborative and dynamic research environment.</p>
            <p>Whether you're interested in robotics, AI, hardware design, or software development, this project offers a unique opportunity to contribute to groundbreaking research and development. This project is designed for a 7-member Undergraduate + Masters team.</p>
        </div>
        <div class="card">
            <h3>Motivation</h3>
            <p>In the rapidly evolving fields of robotics and generative AI, deploying advanced models often relies on deep learning to handle a diverse range of tasks. These tasks span from basic object detection to sophisticated challenges such as predicting the next best view in a 3D scene. Central to the success of these models is the use of automatic differentiation engines, which compute the derivatives of mathematical functions. These computations, whether simple or complex, are fundamental to deep learning training and are executed millions of times, making their speed and efficiency crucial.</p>
            <p>Our project aims to discover and implement innovative methods, techniques, and algorithms that enhance the efficiency and effectiveness of these computational processes. In artificial intelligence, improving efficiency often translates to cost-effectiveness. Thus, our research targets one of AI's most pressing concerns: sustainable and efficient deployment.</p>
            <p>Algorithms, despite their inherent complexities, must be computationally practical to be viable. In AI, the importance of speed goes beyond theoretical performance, emphasizing real-time execution with wall-clock time as the ultimate measure. The vast and dynamic nature of this field means that even small, novel improvements can have a significant impact on both practitioners and researchers in deep learning, driving meaningful advancements in the domain.</p>
            <p>By addressing these objectives, we aim to make significant contributions to the efficiency of deep learning models, ultimately benefiting the broader AI and robotics communities.</p>
        </div>
        <div class="card">
            <h2>About the Project</h2>
                <p><strong>Gradients on the Clock</strong> embarks on the essential groundwork and prototype development phase, aimed at creating a cutting-edge computational framework(s). This project uniquely integrates microcontrollers, Field-Programmable Gate Arrays (FPGAs), and GPUs/CPUs on a standard machine to facilitate core operations in gradient descent, crucial for the process of automatic differentiation. The core objective is to track the time, energy, and FLOps necessary for performing basic gradient descent on microprocessors and find the computationally cheapest means of achieving online learning on an FPGA with a microprocessing interface. This system is designed to bridge the gap between theoretical AI concepts and practical hardware applications, providing an educational foundation in the integral aspects of hardware and software integration for AI and specifically <a href ="https://www.tinyml.org">TinyML</a>.</p>
                <h3>Project Goals</h3>
                <ul>
                    <li><strong>System Architecture Design:</strong> The project begins with the meticulous selection and integration of high-performance microcontrollers and FPGA boards. This stage covers extensive educational content on <a href="https://www.arduino.cc/">microcontroller programming</a> and <a href="https://www.xilinx.com/products/design-tools/vivado.html">FPGA customization</a>. The integration also includes setting up robust communication protocols between these components and PCs to ensure seamless data flow and processing capabilities.</li>
                    <li><strong>Advanced Gradient Computation Techniques:</strong> We are setting up to implement and refine optimization algorithms that operate under strict computational and memory constraints. This exploration includes the creation of optimized interfaces with both local and cloud storage solutions, prominently featuring platforms such as <a href="https://cloud.google.com/">Google Cloud</a> and <a href="https://aws.amazon.com/">AWS</a>. The aim is to facilitate scalable and efficient cloud computation models that integrate smoothly with our hardware setup.</li>
                    <li><strong>Algorithm Benchmarking and Optimization:</strong> Detailed testing of gradient descent and automatic differentiation operations is conducted to enhance their performance and reliability. This phase involves the use of sophisticated analytical tools like <a href="https://www.tensorflow.org/">TensorFlow</a> and <a href="https://pytorch.org/">PyTorch</a>, enabling us to measure and optimize the algorithms' functionality across different hardware setups.</li>
                    <li><strong>Academic Integration and Global Collaboration:</strong> This project is not only about technical development but also about creating a global collaborative environment. We continually engage with current research, and maintain an interactive, up-to-date project website to document and share our findings. This helps participants develop their skills in digital communication and web development, using comprehensive resources like <a href="https://scholar.google.com/">Google Scholar</a> for literature reviews on the cutting edge of this field.</li>
                </ul>
            <h3>Possible Learning Outcomes</h3>
            <p>Participants will gain a multi-dimensional educational experience, achieving the following enhanced learning outcomes:</p>
            <ul>
                <li>Develop deep technical skills in programming microcontrollers and FPGAs, crucial for creating embedded systems that integrate AI capabilities.</li>
                <li>Design and implement energy-efficient hardware setups with a focus on scalability and long-term operation.</li>
                <li>Master the art of performance analysis and algorithm optimization across various hardware platforms, ensuring optimal efficiency and effectiveness.</li>
                <li>Advance their research and technical writing skills through regular updates and contributions to the project's digital platforms.</li>
                <li>Learn to configure and utilize major machine learning libraries, adapting them to run efficiently on microcontroller and FPGA based environments.</li>
                <li>Engage with a global community of researchers and developers through collaborative projects and forums, enhancing professional networking and knowledge exchange.</li>
            </ul>
            <h3>Motivating References</h3>
            <ul>
                <li>Baydin et al., <em>Automatic Differentiation in Machine Learning: A Survey</em>. <a href="https://doi.org/10.48550/arXiv.1502.05767">https://doi.org/10.48550/arXiv.1502.05767</a></li>
                <li>Piercy and Steur in the European Journal of Operations Research, <em>Reducing wall-clock time for the computation of all efficient extreme points in multiple objective linear programming</em>.</li>
                <li>Metz et al., <em>Learned optimizers that outperform on wall-clock and validation loss</em>, ICLR 2019.</li>
                <li>Goodfellow, Bengio, and Courville, <em>Deep Learning</em>, MIT Press, widely regarded as a seminal text in deep learning covering a range of topics including neural networks and hardware optimizations. <a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></li>
                <li>Shewchuk, <em>An Introduction to the Conjugate Gradient Method Without the Agonizing Pain</em>, a fundamental read on optimization techniques applicable to hardware-accelerated systems. <a href="https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf">https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf</a></li>
            </ul>

            <p><strong>In case I have overwhelmed you with details, relax, this project will be performed in phases dependending on the feasibility and teams' expertise. Note that I will be providing a Basys3 FPGA board and Arduino MEGA 2560 microprocessor. I will also be providing for additional components as required.</strong></p>
        </div>
        <div class="card">
            <h2>Project Opportunities</h2>
            <p>Join an ambitious, student-led Open Source Project at the forefront of AI and hardware interaction. This is a unique opportunity to publish novel insights and contribute to transformative open-source AI research. By participating, you'll gain hands-on experience in hardware engineering, deep learning applications, robotics, and the mathematics of optimization. You'll enhance your technical skills and collaborate on a public platform that bridges the academic and industrial spheres.</p>
            <h2>Participant Requirements</h2>
            <p>We're seeking applicants with a robust foundation in university-level calculus and proficiency in Python. While prior knowledge of microprocessor programming and software development tools like Xilinx Vivado and Arduino is advantageous, it's not mandatory. Familiarity with web development (HTML, JavaScript, CSS) will also be helpful for contributing to our project documentation. Be prepared to acquire a diverse set of skills over the course of two semesters.</p>
            <p><strong>Additional Requirements:</strong> Candidates must demonstrate strong analytical thinking and problem-solving skills. Experience with any machine learning frameworks like TensorFlow or PyTorch is highly desirable but not required. Commitment to collaborative development and an eagerness to learn new technologies are crucial. Applicants should also be ready to engage with both theoretical and practical aspects of the project, including participating in discussions, writing reports, and implementing prototypes.</p>
        </div>
        <div class="card">
            <h2>Join Us</h2>
            <p>This project is open to ANU School of Computing students as part of the Techlauncher program for the S2 2024 intake. We're actively seeking motivated students to join the inaugural team. This project is listed in the ANU Techlauncher redmine account. For more information, please <a href="https://1ssb.github.io/contact/">contact me</a>.</p>
        </div>
    </div>
    <footer>
        &copy; <a href="https://1ssb.github.io/">Subhransu S. Bhattacharjee</a>,  <span id="currentYear"></span>
    </footer>
    <script>
        const themeToggle = document.getElementById('themeToggle');
        themeToggle.addEventListener('click', () => {
            const isDarkMode = document.body.classList.toggle('dark-mode');
            const icon = themeToggle.querySelector('i');
            icon.className = isDarkMode ? 'fas fa-sun' : 'fas fa-moon';
            themeToggle.setAttribute('aria-label', isDarkMode ? 'Switch to light mode' : 'Switch to dark mode');
        });

        
        document.getElementById('currentYear').textContent = new Date().getFullYear();
    </script>
</body>
</html>
